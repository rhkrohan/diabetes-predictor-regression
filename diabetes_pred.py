# -*- coding: utf-8 -*-
"""Diabetes Pred.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-P47G9GdN-NRtrX5JUdw-x_9rD2wH1oh

##Importing the Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""##Importing the Dataset"""

dataset = pd.read_csv('diabetes_data_upload.csv')
dataset.head()

"""##Seperation of Dependent and Independent Variables"""

X = dataset.iloc[:, :-1]
y = dataset.iloc[:, -1]

print(X)

print(y)

"""##Data Preprocessing"""

from sklearn.preprocessing import OrdinalEncoder
encoder = OrdinalEncoder()
X.iloc[:, 1:] = encoder.fit_transform(X.iloc[:, 1:])

print(X)

y = y.reshape(len(y), 1)
y = encoder.fit_transform(y)

print(y)

"""##Splitting Data into Training and Test Sets"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

"""##Building the Multiple Linear Regression Model"""

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train, y_train)

"""##Predicting Results and Evaluating Model Performance"""

y_pred = regressor.predict(X_test)

print(y_pred)

from sklearn.metrics import r2_score
r2_score(y_test, y_pred)

"""##Determining Percentage Acuracy on Test Results"""

def accuracy(x_test, y_test, y_pred):
    correct = 0
    for i in range(len(y_pred)):
        if np.round(y_pred[i]) == y_test[i]:
            correct += 1
    accuracy = (correct / len(y_pred)) * 100
    return accuracy

accuracy_score = accuracy(X_test, y_test, y_pred)
print(f"Accuracy: {accuracy_score}%")

"""##Visualising the results"""

# Scatter plot of actual vs. predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='blue')
plt.plot([0, 1], [0, 1], '--', color='red')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted Values')
plt.show()

# Histogram of residuals
residuals = y_test - y_pred
plt.figure(figsize=(10, 6))
plt.hist(residuals, bins=20, edgecolor='k')
plt.xlabel('Residual')
plt.ylabel('Frequency')
plt.title('Histogram of Residuals')
plt.show()

# Learning curve
from sklearn.model_selection import learning_curve

train_sizes, train_scores, test_scores = learning_curve(regressor, X, y, cv=5, scoring='r2',
                                                        train_sizes=np.linspace(0.1, 1.0, 10))

train_scores_mean = np.mean(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training score')
plt.plot(train_sizes, test_scores_mean, 'o-', color='green', label='Cross-validation score')
plt.xlabel('Training examples')
plt.ylabel('Score')
plt.title('Learning Curve')
plt.legend(loc='best')
plt.show()